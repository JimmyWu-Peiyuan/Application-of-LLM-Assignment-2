{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Assignment - Step 1: Domain Documents Exploration\n",
        "\n",
        "## Dataset Setup and Exploration Report\n",
        "\n",
        "This notebook explores the RAG Mini Wikipedia dataset to understand its structure, content, and data quality for our retrieval-augmented generation system.\n",
        "\n",
        "**Dataset**: `rag-datasets/rag-mini-wikipedia`\n",
        "- **Passages**: Wikipedia passages for retrieval\n",
        "- **Questions**: Test questions for evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jimmywu/Documents/school/cmu/nl(x)/Application-of-LLM-Assignment-2/assignment2-rag/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import datasets\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Access and Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading RAG Mini Wikipedia passages dataset...\n",
            "Passages dataset loaded successfully!\n",
            "Shape: (3200, 1)\n",
            "Columns: ['passage']\n"
          ]
        }
      ],
      "source": [
        "# Load the passages dataset\n",
        "print(\"Loading RAG Mini Wikipedia passages dataset...\")\n",
        "passages_df = pd.read_parquet(\"hf://datasets/rag-datasets/rag-mini-wikipedia/data/passages.parquet/part.0.parquet\")\n",
        "\n",
        "print(\"Passages dataset loaded successfully!\")\n",
        "print(f\"Shape: {passages_df.shape}\")\n",
        "print(f\"Columns: {list(passages_df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>passage</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Uruguay (official full name in  ; pron.  , Eas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It is bordered by Brazil to the north, by Arge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Montevideo was founded by the Spanish in the e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The economy is largely based in agriculture (m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>According to Transparency International, Urugu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              passage\n",
              "id                                                   \n",
              "0   Uruguay (official full name in  ; pron.  , Eas...\n",
              "1   It is bordered by Brazil to the north, by Arge...\n",
              "2   Montevideo was founded by the Spanish in the e...\n",
              "3   The economy is largely based in agriculture (m...\n",
              "4   According to Transparency International, Urugu..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "passages_df.head(\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading RAG Mini Wikipedia test questions dataset...\n",
            "Test questions dataset loaded successfully!\n",
            "Shape: (918, 2)\n",
            "Columns: ['question', 'answer']\n"
          ]
        }
      ],
      "source": [
        "# Load the test questions dataset\n",
        "print(\"Loading RAG Mini Wikipedia test questions dataset...\")\n",
        "test_df = pd.read_parquet(\"hf://datasets/rag-datasets/rag-mini-wikipedia/data/test.parquet/part.0.parquet\")\n",
        "\n",
        "print(\"Test questions dataset loaded successfully!\")\n",
        "print(f\"Shape: {test_df.shape}\")\n",
        "print(f\"Columns: {list(test_df.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Understanding: Document Dataset Structure, Sample Entries, and Data Quality Observations\n",
        "\n",
        "This section provides a comprehensive analysis of both datasets to understand their structure, content, and quality for RAG system development.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Passages Dataset Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset overview\n",
            "Dataset shape: (3200, 1)\n",
            "Columns: ['passage']\n",
            "Data types:\n",
            "passage    string[python]\n",
            "dtype: object\n",
            "Memory usage: 1.40 MB\n",
            "Missing values: 0\n",
            "Duplicate passages: 4\n"
          ]
        }
      ],
      "source": [
        "# Basic structure analysis of passages dataset\n",
        "print(\"Dataset overview\")\n",
        "print(f\"Dataset shape: {passages_df.shape}\")\n",
        "print(f\"Columns: {list(passages_df.columns)}\")\n",
        "print(f\"Data types:\\n{passages_df.dtypes}\")\n",
        "print(f\"Memory usage: {passages_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(f\"Missing values: {passages_df.isnull().sum().sum()}\")\n",
        "print(f\"Duplicate passages: {passages_df.duplicated().sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== PASSAGE WORD COUNT STATISTICS ===\n",
            "Word count - Mean: 62.1\n",
            "Word count - Median: 48.0\n",
            "Word count - Min: 1\n",
            "Word count - Max: 425\n"
          ]
        }
      ],
      "source": [
        "# Passage word count analysis\n",
        "passages_df['word_count'] = passages_df['passage'].str.split().str.len()\n",
        "\n",
        "print(\"\\n=== PASSAGE WORD COUNT STATISTICS ===\")\n",
        "print(f\"Word count - Mean: {passages_df['word_count'].mean():.1f}\")\n",
        "print(f\"Word count - Median: {passages_df['word_count'].median():.1f}\")\n",
        "print(f\"Word count - Min: {passages_df['word_count'].min()}\")\n",
        "print(f\"Word count - Max: {passages_df['word_count'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== PASSAGE WORD COUNT STATISTICS ===\n",
            "Word count - Mean: 62.1\n",
            "Word count - Median: 48.0\n",
            "Word count - Min: 1\n",
            "Word count - Max: 425\n"
          ]
        }
      ],
      "source": [
        "# Passage word count analysis\n",
        "passages_df['word_count'] = passages_df['passage'].str.split().str.len()\n",
        "\n",
        "print(\"\\n=== PASSAGE WORD COUNT STATISTICS ===\")\n",
        "print(f\"Word count - Mean: {passages_df['word_count'].mean():.1f}\")\n",
        "print(f\"Word count - Median: {passages_df['word_count'].median():.1f}\")\n",
        "print(f\"Word count - Min: {passages_df['word_count'].min()}\")\n",
        "print(f\"Word count - Max: {passages_df['word_count'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                               passage  word_count\n",
            "id                                                \n",
            "28                      Map of Uruguay           3\n",
            "30                    and with Brazil:           3\n",
            "36      Montevideo, Uruguay's capital.           3\n",
            "46                   INE, (in Spanish)           3\n",
            "71    ;Political and economic rankings           4\n",
            "...                                ...         ...\n",
            "3159                         Overviews           1\n",
            "3160                     Travel guides           2\n",
            "3161             Economy and law links           4\n",
            "3162      Culture and history links              4\n",
            "3179            Duck headcount in 2004           4\n",
            "\n",
            "[185 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# find the passages with little word counts\n",
        "passages_check = passages_df.copy()\n",
        "passages_check = passages_check[passages_check['word_count'] <5]\n",
        "print(passages_check)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== SAMPLE QUESTIONS AND ANSWERS ===\n",
            "First 5 question-answer pairs:\n",
            "\n",
            "--- Q&A Pair 1 ---\n",
            "Question: Was Abraham Lincoln the sixteenth President of the United States?\n",
            "Answer: yes\n",
            "Question length: 65 chars\n",
            "Answer length: 3 chars\n",
            "\n",
            "--- Q&A Pair 2 ---\n",
            "Question: Did Lincoln sign the National Banking Act of 1863?\n",
            "Answer: yes\n",
            "Question length: 50 chars\n",
            "Answer length: 3 chars\n",
            "\n",
            "--- Q&A Pair 3 ---\n",
            "Question: Did his mother die of pneumonia?\n",
            "Answer: no\n",
            "Question length: 32 chars\n",
            "Answer length: 2 chars\n",
            "\n",
            "--- Q&A Pair 4 ---\n",
            "Question: How many long was Lincoln's formal education?\n",
            "Answer: 18 months\n",
            "Question length: 45 chars\n",
            "Answer length: 9 chars\n",
            "\n",
            "--- Q&A Pair 5 ---\n",
            "Question: When did Lincoln begin his political career?\n",
            "Answer: 1832\n",
            "Question length: 44 chars\n",
            "Answer length: 4 chars\n"
          ]
        }
      ],
      "source": [
        "# Sample questions and answers for content analysis\n",
        "print(\"\\n=== SAMPLE QUESTIONS AND ANSWERS ===\")\n",
        "print(\"First 5 question-answer pairs:\")\n",
        "for i in range(5):\n",
        "    print(f\"\\n--- Q&A Pair {i+1} ---\")\n",
        "    print(f\"Question: {test_df.iloc[i]['question']}\")\n",
        "    print(f\"Answer: {test_df.iloc[i]['answer']}\")\n",
        "    print(f\"Question length: {len(test_df.iloc[i]['question'])} chars\")\n",
        "    print(f\"Answer length: {len(test_df.iloc[i]['answer'])} chars\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== QUESTION LENGTH STATISTICS ===\n",
            "Character length - Mean: 53.1, Std: 28.5\n",
            "Character length - Min: 4, Max: 252\n",
            "Word count - Mean: 9.1, Std: 5.1\n",
            "\n",
            "=== ANSWER LENGTH STATISTICS ===\n",
            "Character length - Mean: 19.2, Std: 35.0\n",
            "Character length - Min: 1, Max: 423\n",
            "Word count - Mean: 3.4, Std: 5.5\n"
          ]
        }
      ],
      "source": [
        "# Question and answer length analysis\n",
        "test_df['question_length'] = test_df['question'].str.len()\n",
        "test_df['answer_length'] = test_df['answer'].str.len()\n",
        "test_df['question_word_count'] = test_df['question'].str.split().str.len()\n",
        "test_df['answer_word_count'] = test_df['answer'].str.split().str.len()\n",
        "\n",
        "print(\"\\n=== QUESTION LENGTH STATISTICS ===\")\n",
        "print(f\"Character length - Mean: {test_df['question_length'].mean():.1f}, Std: {test_df['question_length'].std():.1f}\")\n",
        "print(f\"Character length - Min: {test_df['question_length'].min()}, Max: {test_df['question_length'].max()}\")\n",
        "print(f\"Word count - Mean: {test_df['question_word_count'].mean():.1f}, Std: {test_df['question_word_count'].std():.1f}\")\n",
        "\n",
        "print(\"\\n=== ANSWER LENGTH STATISTICS ===\")\n",
        "print(f\"Character length - Mean: {test_df['answer_length'].mean():.1f}, Std: {test_df['answer_length'].std():.1f}\")\n",
        "print(f\"Character length - Min: {test_df['answer_length'].min()}, Max: {test_df['answer_length'].max()}\")\n",
        "print(f\"Word count - Mean: {test_df['answer_word_count'].mean():.1f}, Std: {test_df['answer_word_count'].std():.1f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Data Quality Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== TEST QUESTIONS DATA QUALITY ANALYSIS ===\n",
            "Empty questions: 0\n",
            "Empty answers: 0\n",
            "Very short questions (<5 chars): 1\n",
            "Very short answers (<2 chars): 3\n",
            "Questions not ending with '?': 10\n",
            "Potential placeholder answers: 0\n",
            "Very long answers (>1000 chars): 0\n",
            "\n",
            "Sample very short questions:\n",
            "  Index 574: 'hard'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6f/1wc1hr014gv_1g24l_md37100000gn/T/ipykernel_84983/681365557.py:20: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  placeholder_answers = test_df['answer'].str.lower().str.contains(r'^(n/a|none|null|tbd|unknown)$', na=False)\n"
          ]
        }
      ],
      "source": [
        "# Data quality checks for test questions\n",
        "print(\"\\n=== TEST QUESTIONS DATA QUALITY ANALYSIS ===\")\n",
        "\n",
        "# Check for empty or very short questions/answers\n",
        "empty_questions = test_df['question'].str.strip().str.len() == 0\n",
        "empty_answers = test_df['answer'].str.strip().str.len() == 0\n",
        "very_short_questions = test_df['question_length'] < 5\n",
        "very_short_answers = test_df['answer_length'] < 2\n",
        "\n",
        "print(f\"Empty questions: {empty_questions.sum()}\")\n",
        "print(f\"Empty answers: {empty_answers.sum()}\")\n",
        "print(f\"Very short questions (<5 chars): {very_short_questions.sum()}\")\n",
        "print(f\"Very short answers (<2 chars): {very_short_answers.sum()}\")\n",
        "\n",
        "# Check for questions that might be incomplete or malformed\n",
        "incomplete_questions = ~test_df['question'].str.endswith('?')\n",
        "print(f\"Questions not ending with '?': {incomplete_questions.sum()}\")\n",
        "\n",
        "# Check for answers that might be placeholders\n",
        "placeholder_answers = test_df['answer'].str.lower().str.contains(r'^(n/a|none|null|tbd|unknown)$', na=False)\n",
        "print(f\"Potential placeholder answers: {placeholder_answers.sum()}\")\n",
        "\n",
        "# Check for very long answers (might indicate data issues)\n",
        "very_long_answers = test_df['answer_length'] > 1000\n",
        "print(f\"Very long answers (>1000 chars): {very_long_answers.sum()}\")\n",
        "\n",
        "# Sample some potential issues\n",
        "if very_short_questions.any():\n",
        "    print(f\"\\nSample very short questions:\")\n",
        "    for idx in test_df[very_short_questions].index[:3]:\n",
        "        print(f\"  Index {idx}: '{test_df.loc[idx, 'question']}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Looking at the question answer pair that have very little words \n",
        "# Check for empty or very short questions/answers\n",
        "empty_questions = test_df['question'].str.strip().str.len() == 0\n",
        "empty_answers = test_df['answer'].str.strip().str.len() == 0\n",
        "very_short_questions = test_df['question_length'] < 15\n",
        "very_short_answers = test_df['answer_length'] < 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<StringArray>\n",
              "[ 'yes',   'no', '1832', '1776',   'No',  'Yes', '1846', '1821', '1820',\n",
              " '1733', 'Yes.', '1905', '1898',  'No.',  '28%', '1545',  'no!', 'Meat',\n",
              " '1967',    '2',    '1', 'Ears', '1952',  'CMX', 'hard',  '400', '1957',\n",
              "   '10',    '5', '1890', '1999',   '28', '1814', '1994', '1836',   '11',\n",
              "   '6.', '1861', 'Weed', 'yes.',   '13', 'Holt',  '41.',   '2.', '2007',\n",
              " 'lion', '1959',  'air', 'Yolk', 'eggs', '1868', '1856',  '88%',  'No?']\n",
              "Length: 54, dtype: string"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df[very_short_answers]['answer'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<StringArray>\n",
              "['hard', 'What is a roo?']\n",
              "Length: 2, dtype: string"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df[very_short_questions]['question'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
